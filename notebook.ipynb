{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import subprocess\n",
    "import os\n",
    "import uuid\n",
    "import re\n",
    "import json\n",
    "from utils import clean_text\n",
    "import pathlib\n",
    "\n",
    "ANYSTYPE_PATH=\"/home/viet/.local/share/gem/ruby/3.2.0/bin/anystyle\"\n",
    "\n",
    "def extract_references_and_citations(text, name=None):\n",
    "    \n",
    "    # Find the reference section\n",
    "    text = clean_text(text)\n",
    "    reference_section = re.search(r'References([\\s\\S]*)', text, re.IGNORECASE)\n",
    "    if reference_section:\n",
    "        references = reference_section.group(1)\n",
    "    else:\n",
    "        return \"References section not found.\"\n",
    "    \n",
    "    # Extract individual references\n",
    "    reference_list = re.findall(r'\\[\\d+\\].*?(?=\\[\\d+\\]|\\Z)', references, re.DOTALL)\n",
    "    \n",
    "    # Find in-text citations\n",
    "    citations = re.findall(r'\\[(\\d+)\\]', text)\n",
    "\n",
    "    reference_list = [ref.replace('\\n','') for ref in reference_list]\n",
    "\n",
    "    if name:\n",
    "        json.dump({\n",
    "            \"references\": reference_list,\n",
    "            \"citations\": citations,\n",
    "        }, open(f\"tmp/{name}_references.json\", \"w\"), indent=4)\n",
    "    \n",
    "    return reference_list, citations\n",
    "\n",
    "def parse_pdf2text(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    number_of_pages = len(reader.pages)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "\n",
    "    return text\n",
    "\n",
    "def parse_references(references, work_dir):\n",
    "    file_path = f\"{work_dir}/refs.txt\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for ref in references:\n",
    "            f.write(ref[4:] + '\\n')\n",
    "\n",
    "    process = subprocess.Popen([ANYSTYPE_PATH, 'parse', file_path], \n",
    "                           stdout=subprocess.PIPE, \n",
    "                           stderr=subprocess.PIPE,\n",
    "                           text=True)\n",
    "\n",
    "    stdout, stderr = process.communicate()\n",
    "\n",
    "    if stderr:\n",
    "        raise NameError(stderr)\n",
    "\n",
    "    parsed_refs = json.loads(stdout)\n",
    "\n",
    "    for i, ref in enumerate(references):\n",
    "        parsed_refs[i][\"cite_id\"] = ref[1:2]\n",
    "\n",
    "    return parsed_refs\n",
    "\n",
    "def make_working_dir():\n",
    "    paper_uuid = uuid.uuid4()\n",
    "    working_dir = f\"tmp/{paper_uuid}/\"\n",
    "    pathlib.Path(working_dir).mkdir(parents=True, exist_ok=True)\n",
    "    return working_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests\n",
    "from arxvi_utils import parse_arxiv_response\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "def tfidf_similarity(text1, text2):\n",
    "    # Create TfidfVectorizer object\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    # Fit and transform the texts\n",
    "    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    \n",
    "    return similarity[0][0]\n",
    "\n",
    "def crossref_search(reference):\n",
    "    params = {\n",
    "        'query': reference\n",
    "    }\n",
    "    r = requests.get(\"https://api.crossref.org/works\", params= params)\n",
    "    \n",
    "    return r.json()['message']['items'][0]\n",
    "\n",
    "def get_paper_link(doi):\n",
    "    URL = f\"https://doi.org/{doi}\" # Specify the DOI here\n",
    "    r = requests.get(URL,allow_redirects=True) # Redirects help follow to the actual domain\n",
    "    return r.url\n",
    "\n",
    "def arxiv_search(reference):\n",
    "    params = {\n",
    "        \"search_query\": reference,\n",
    "        \"start\": 0,\n",
    "        \"max_results\": 1,\n",
    "    }\n",
    "\n",
    "    response = requests.get(\"http://export.arxiv.org/api/query\", params=params) \n",
    "    parsed_res = parse_arxiv_response(response.text)\n",
    "    if len(parsed_res) != 0:\n",
    "        return parsed_res[0]\n",
    "    else:\n",
    "        return {\n",
    "            \"title\": \"\",\n",
    "            \"id\": \"\"\n",
    "        }\n",
    "\n",
    "def retrieve_from_crossref(parsed_ref):\n",
    "    search_results = {\n",
    "        'tf-idf_score': [],\n",
    "        'ref_title': [],\n",
    "        'res_title': [],\n",
    "        'res_DOI': [],\n",
    "        'paper_link': []\n",
    "    }\n",
    "\n",
    "    for ref in tqdm(parsed_ref):\n",
    "        ref_text_title = ref[\"title\"][0]\n",
    "        search_result = crossref_search(ref_text_title)\n",
    "        search_result_title = search_result['title'][0]\n",
    "        doi = search_result['DOI']\n",
    "        paper_link = get_paper_link(doi)\n",
    "        sim_score = tfidf_similarity(ref_text_title, search_result_title)\n",
    "\n",
    "        search_results['ref_title'].append(ref_text_title)\n",
    "        search_results['res_title'].append(search_result_title)\n",
    "        search_results['res_DOI'].append(doi)\n",
    "        search_results['tf-idf_score'].append(sim_score)\n",
    "        search_results['paper_link'].append(paper_link)\n",
    "        \n",
    "        # print(f\"{sim_score} | {ref_text_title} | {search_result_title}\")\n",
    "\n",
    "\n",
    "    retrieve_df = pd.DataFrame(search_results)\n",
    "    # retrieve_df.to_csv(\"tmp/retrieve_table.csv\")\n",
    "    return retrieve_df\n",
    "\n",
    "def retrieve_from_arxiv(parsed_ref):\n",
    "    arvix_search_results = {\n",
    "        'cite_id': [],\n",
    "        'tf-idf_score': [],\n",
    "        'ref_title': [],\n",
    "        'res_title': [],\n",
    "        'arxiv_id': []\n",
    "    }\n",
    "\n",
    "    for ref in tqdm(parsed_ref):\n",
    "        ref_text_title = ref[\"title\"][0]\n",
    "        search_result = arxiv_search(ref_text_title)\n",
    "        search_result_title = search_result['title']\n",
    "        search_result_id = search_result['id'].split(\"/\")[-1]\n",
    "        sim_score = tfidf_similarity(ref_text_title, search_result_title)\n",
    "        \n",
    "        arvix_search_results['cite_id'].append(ref['cite_id'])\n",
    "        arvix_search_results['ref_title'].append(ref_text_title)\n",
    "        arvix_search_results['res_title'].append(search_result_title)\n",
    "        arvix_search_results['tf-idf_score'].append(sim_score)\n",
    "        arvix_search_results['arxiv_id'].append(search_result_id)\n",
    "\n",
    "    retrieve_df = pd.DataFrame(arvix_search_results)\n",
    "    # retrieve_df.to_csv(\"tmp/arvix_retrieve_table.csv\")\n",
    "\n",
    "    return retrieve_df\n",
    "\n",
    "def retrieve_from_crossref(parsed_ref):\n",
    "    arvix_search_results = {\n",
    "        'cite_id': [],\n",
    "        'tf-idf_score': [],\n",
    "        'ref_title': [],\n",
    "        'res_title': [],\n",
    "        'URL': []\n",
    "    }\n",
    "\n",
    "    for ref in tqdm(parsed_ref):\n",
    "        ref_text_title = ref[\"title\"][0]\n",
    "        search_result = crossref_search(ref_text_title)\n",
    "        search_result_title = search_result['title'][0]\n",
    "        search_result_url = search_result['URL']\n",
    "        sim_score = tfidf_similarity(ref_text_title, search_result_title)\n",
    "        \n",
    "        arvix_search_results['cite_id'].append(ref['cite_id'])\n",
    "        arvix_search_results['ref_title'].append(ref_text_title)\n",
    "        arvix_search_results['res_title'].append(search_result_title)\n",
    "        arvix_search_results['tf-idf_score'].append(sim_score)\n",
    "        arvix_search_results['URL'].append(search_result_url)\n",
    "\n",
    "    retrieve_df = pd.DataFrame(arvix_search_results)\n",
    "\n",
    "    return retrieve_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARXIV_PDF_URL = \"http://export.arxiv.org/pdf/\"\n",
    "\n",
    "def download_papers(retrieve_df, working_dir):\n",
    "    download_path = f\"{working_dir}/papers\"\n",
    "    mapper = {}\n",
    "    pathlib.Path(download_path).mkdir(exist_ok=True)\n",
    "    for index, row in tqdm(retrieve_df.iterrows()):\n",
    "        arxiv_id = row[\"arxiv_id\"]\n",
    "        cite_id = row[\"cite_id\"]\n",
    "        pdf_url = f\"{ARXIV_PDF_URL}{arxiv_id}\"\n",
    "        response = requests.get(pdf_url)\n",
    "\n",
    "        save_path = f\"{download_path}/{arxiv_id}.pdf\"\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(response.content) \n",
    "\n",
    "        mapper[cite_id] = save_path\n",
    "\n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages\n",
    "import re\n",
    "from pdfminer.layout import LTTextBoxHorizontal, LTTextBox, LTTextLine, LTChar\n",
    "from utils import clean_text\n",
    "\n",
    "def is_reference_header(text):\n",
    "    \"\"\"Check if the given text is likely to be a reference section header.\"\"\"\n",
    "    reference_headers = ['references', 'bibliography', 'works cited', 'literature cited']\n",
    "    return any(header in text.lower() for header in reference_headers)\n",
    "\n",
    "def extract_citation(text, element_info):\n",
    "    citation_pattern = r'\\[(\\d+(?:,\\s*\\d+)*)\\]'\n",
    "\n",
    "    citations = re.findall(citation_pattern, text)\n",
    "    citation_sentences = []\n",
    "    if citations:\n",
    "        # Split text into sentences (simple split on period)\n",
    "        sentences = text.split('.')\n",
    "        for sentence in sentences:\n",
    "            if re.search(citation_pattern, sentence):\n",
    "                # cleaned_text = clean_text(sentence.strip())\n",
    "                # cleaned_text = cleaned_text.replace('\\n', ' ').replace('- ', '')\n",
    "                cleaned_text = sentence\n",
    "                citation_sentences.append(cleaned_text)\n",
    "\n",
    "        citations = []\n",
    "        citation_sentences = []\n",
    "\n",
    "        for sentence in citation_sentences:\n",
    "            cites = re.findall(citation_pattern, sentence)\n",
    "            for citation in cites:\n",
    "                splitted_cites = citation.split(', ')\n",
    "                for cite in splitted_cites:\n",
    "                    citations.append(int(cite))\n",
    "                    citation_sentences.append(sentence)\n",
    "\n",
    "        element_info[\"citations\"] = citations\n",
    "        element_info[\"citation_sentences\"] = citation_sentences\n",
    "    \n",
    "    # return element_info\n",
    "\n",
    "def extract_element_boxes(pdf_path, get_citation=False):\n",
    "    \n",
    "    # Extract pages using PDFMiner\n",
    "    pages = list(extract_pages(pdf_path))\n",
    "    \n",
    "    # Initialize list to store all text elements\n",
    "    all_elements = []\n",
    "    \n",
    "    for page_num, page in enumerate(pages, start=1):\n",
    "        \n",
    "        # Get page dimensions\n",
    "        pdf_width = page.width\n",
    "        pdf_height = page.height\n",
    "        \n",
    "        # Iterate through layout objects on the page\n",
    "        for element in page:\n",
    "            if hasattr(element, 'get_text'): \n",
    "                # isinstance(element, (LTTextBoxHorizontal, LTTextBox, LTTextLine, LTChar)):\n",
    "                # Get coordinates\n",
    "                x0, y0, x1, y1 = element.bbox\n",
    "                \n",
    "                # Normalize coordinates\n",
    "                x0_norm = x0 / pdf_width\n",
    "                x1_norm = x1 / pdf_width\n",
    "                y0_norm = y0 / pdf_height\n",
    "                y1_norm = y1 / pdf_height\n",
    "                \n",
    "                # Add text with element type\n",
    "                element_type = type(element).__name__\n",
    "                \n",
    "                # Extract text content\n",
    "                text = \"\"\n",
    "                text = element.get_text().strip()\n",
    "\n",
    "                if is_reference_header(text):\n",
    "                    continue\n",
    "\n",
    "                element_info = {\n",
    "                    \"type\": element_type,\n",
    "                    \"page\": page_num,\n",
    "                    \"bbox\": [x0_norm, y0_norm, x1_norm, y1_norm],\n",
    "                    \"text\": text,\n",
    "                }\n",
    "\n",
    "                if get_citation:                \n",
    "                    extract_citation(text, element_info)                   \n",
    "\n",
    "                all_elements.append(element_info)\n",
    "    \n",
    "    return all_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_path = \"papers/1403.6382v3.pdf\"\n",
    "\n",
    "working_dir = make_working_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [04:32<00:00,  5.24s/it]\n"
     ]
    }
   ],
   "source": [
    "text = parse_pdf2text(paper_path)\n",
    "reference_list, citations = extract_references_and_citations(text)\n",
    "parsed_refs = parse_references(reference_list, working_dir)\n",
    "\n",
    "# retrieve_df = retrieve_from_arxiv(parsed_refs)\n",
    "retrieve_df = retrieve_from_crossref(parsed_refs)\n",
    "retrieve_df = retrieve_df[retrieve_df[\"tf-idf_score\"] > 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cite_id</th>\n",
       "      <th>tf-idf_score</th>\n",
       "      <th>ref_title</th>\n",
       "      <th>res_title</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>Imagenet large scale visual recognition challe...</td>\n",
       "      <td>ImageNet Large Scale Visual Recognition Challenge</td>\n",
       "      <td>http://dx.doi.org/10.1007/s11263-015-0816-y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Efficient object detection and segmentation fo...</td>\n",
       "      <td>Efficient Object Detection and Segmentation fo...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2013.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>All about VLAD</td>\n",
       "      <td>All About VLAD</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2013.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.711559</td>\n",
       "      <td>Poof: Part-based one-vs.-onefeatures for fine-...</td>\n",
       "      <td>POOF: Part-Based One-vs.-One Features for Fine...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2013.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.779915</td>\n",
       "      <td>Describing people: Aposelet-based approach to ...</td>\n",
       "      <td>Describing people: A poselet-based approach to...</td>\n",
       "      <td>http://dx.doi.org/10.1109/iccv.2011.6126413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.706078</td>\n",
       "      <td>Bicos: A bilevel co-segmentation method for im...</td>\n",
       "      <td>BiCoS: A Bi-level co-segmentation method for i...</td>\n",
       "      <td>http://dx.doi.org/10.1109/iccv.2011.6126546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.895532</td>\n",
       "      <td>Hierarchical matching with side information fo...</td>\n",
       "      <td>Hierarchical matching with side information fo...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2012.6248083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.818180</td>\n",
       "      <td>Yan.Subcategory-aware object classification</td>\n",
       "      <td>Subcategory-Aware Object Classification</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2013.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Describing objects by their attributes</td>\n",
       "      <td>Describing objects by their attributes</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvprw.2009.5206772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.826728</td>\n",
       "      <td>Negative evidences and cooccurences in image r...</td>\n",
       "      <td>Negative Evidences and Co-occurences in Image ...</td>\n",
       "      <td>http://dx.doi.org/10.1007/978-3-642-33709-3_55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Aggregating local image descriptors into compa...</td>\n",
       "      <td>Aggregating Local Image Descriptors into Compa...</td>\n",
       "      <td>http://dx.doi.org/10.1109/tpami.2011.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0.818180</td>\n",
       "      <td>Zisserman.Blocks that shout: Distinctive parts...</td>\n",
       "      <td>Blocks That Shout: Distinctive Parts for Scene...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2013.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0.706078</td>\n",
       "      <td>Attributebased classification for zero-shot vi...</td>\n",
       "      <td>Attribute-Based Classification for Zero-Shot V...</td>\n",
       "      <td>http://dx.doi.org/10.1109/tpami.2013.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>0.732707</td>\n",
       "      <td>Harvesting mid-level visual conceptsfrom large...</td>\n",
       "      <td>Harvesting Mid-level Visual Concepts from Larg...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2013.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Automated flower classification over a large n...</td>\n",
       "      <td>Automated Flower Classification over a Large N...</td>\n",
       "      <td>http://dx.doi.org/10.1109/icvgip.2008.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Scalable recognition with a vocabulary tree</td>\n",
       "      <td>Scalable Recognition with a Vocabulary Tree</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2006.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>0.754897</td>\n",
       "      <td>Learning andtransferring mid-level image repre...</td>\n",
       "      <td>Learning and Transferring Mid-level Image Repr...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2014.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Reconfigurable models for scene recognition</td>\n",
       "      <td>Reconfigurable models for scene recognition</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2012.6248001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>0.706078</td>\n",
       "      <td>Object retrieval with large vocabularies and f...</td>\n",
       "      <td>Object retrieval with large vocabularies and f...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2007.383172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>0.761039</td>\n",
       "      <td>Zisserman.Lost in quantization: Improving part...</td>\n",
       "      <td>Lost in quantization: Improving particular obj...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2008.4587635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Recognizing indoor scenes</td>\n",
       "      <td>Recognizing indoor scenes</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2009.5206537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>0.801978</td>\n",
       "      <td>Adatabase for fine grained activity detection ...</td>\n",
       "      <td>A database for fine grained activity detection...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2012.6247801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Contextualizing object detection and classific...</td>\n",
       "      <td>Contextualizing object detection and classific...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2011.5995330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>0.706078</td>\n",
       "      <td>Learning discriminative part detectorsfor imag...</td>\n",
       "      <td>Learning Discriminative Part Detectors for Ima...</td>\n",
       "      <td>http://dx.doi.org/10.1109/iccv.2013.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Deepface:Closing the gap to human-level perfor...</td>\n",
       "      <td>DeepFace: Closing the Gap to Human-Level Perfo...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2014.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>0.844021</td>\n",
       "      <td>To aggregate or notto aggregate: Selective mat...</td>\n",
       "      <td>To Aggregate or Not to aggregate: Selective Ma...</td>\n",
       "      <td>http://dx.doi.org/10.1109/iccv.2013.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Deeppose: Human pose estimation via deep neura...</td>\n",
       "      <td>DeepPose: Human Pose Estimation via Deep Neura...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2014.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>0.732707</td>\n",
       "      <td>Sparse representations anddistance learning fo...</td>\n",
       "      <td>Sparse Representations and Distance Learning f...</td>\n",
       "      <td>http://dx.doi.org/10.1007/978-3-642-35749-7_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>A discriminative latent model of object classe...</td>\n",
       "      <td>A Discriminative Latent Model of Object Classe...</td>\n",
       "      <td>http://dx.doi.org/10.1007/978-3-642-15555-0_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4</td>\n",
       "      <td>0.706078</td>\n",
       "      <td>Combining randomizationand discrimination for ...</td>\n",
       "      <td>Combining randomization and discrimination for...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2011.5995368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>0.883128</td>\n",
       "      <td>Pose aligned networks for deep attribute modeling</td>\n",
       "      <td>PANDA: Pose Aligned Networks for Deep Attribut...</td>\n",
       "      <td>http://dx.doi.org/10.1109/cvpr.2014.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5</td>\n",
       "      <td>0.791079</td>\n",
       "      <td>Oriented pooling fordense and non-dense rotati...</td>\n",
       "      <td>Oriented pooling for dense and non-dense rotat...</td>\n",
       "      <td>http://dx.doi.org/10.5244/c.27.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cite_id  tf-idf_score                                          ref_title  \\\n",
       "0        1      0.776515  Imagenet large scale visual recognition challe...   \n",
       "1        2      1.000000  Efficient object detection and segmentation fo...   \n",
       "3        4      1.000000                                     All about VLAD   \n",
       "4        5      0.711559  Poof: Part-based one-vs.-onefeatures for fine-...   \n",
       "5        6      0.779915  Describing people: Aposelet-based approach to ...   \n",
       "6        7      0.706078  Bicos: A bilevel co-segmentation method for im...   \n",
       "7        8      0.895532  Hierarchical matching with side information fo...   \n",
       "10       1      0.818180        Yan.Subcategory-aware object classification   \n",
       "12       1      1.000000             Describing objects by their attributes   \n",
       "17       1      0.826728  Negative evidences and cooccurences in image r...   \n",
       "19       2      1.000000  Aggregating local image descriptors into compa...   \n",
       "20       2      0.818180  Zisserman.Blocks that shout: Distinctive parts...   \n",
       "22       2      0.706078  Attributebased classification for zero-shot vi...   \n",
       "24       2      0.732707  Harvesting mid-level visual conceptsfrom large...   \n",
       "26       2      1.000000  Automated flower classification over a large n...   \n",
       "27       2      1.000000        Scalable recognition with a vocabulary tree   \n",
       "28       2      0.754897  Learning andtransferring mid-level image repre...   \n",
       "30       3      1.000000        Reconfigurable models for scene recognition   \n",
       "33       3      0.706078  Object retrieval with large vocabularies and f...   \n",
       "34       3      0.761039  Zisserman.Lost in quantization: Improving part...   \n",
       "35       3      1.000000                          Recognizing indoor scenes   \n",
       "36       3      0.801978  Adatabase for fine grained activity detection ...   \n",
       "38       3      1.000000  Contextualizing object detection and classific...   \n",
       "39       4      0.706078  Learning discriminative part detectorsfor imag...   \n",
       "40       4      1.000000  Deepface:Closing the gap to human-level perfor...   \n",
       "41       4      0.844021  To aggregate or notto aggregate: Selective mat...   \n",
       "42       4      1.000000  Deeppose: Human pose estimation via deep neura...   \n",
       "43       4      0.732707  Sparse representations anddistance learning fo...   \n",
       "45       4      1.000000  A discriminative latent model of object classe...   \n",
       "46       4      0.706078  Combining randomizationand discrimination for ...   \n",
       "50       5      0.883128  Pose aligned networks for deep attribute modeling   \n",
       "51       5      0.791079  Oriented pooling fordense and non-dense rotati...   \n",
       "\n",
       "                                            res_title  \\\n",
       "0   ImageNet Large Scale Visual Recognition Challenge   \n",
       "1   Efficient Object Detection and Segmentation fo...   \n",
       "3                                      All About VLAD   \n",
       "4   POOF: Part-Based One-vs.-One Features for Fine...   \n",
       "5   Describing people: A poselet-based approach to...   \n",
       "6   BiCoS: A Bi-level co-segmentation method for i...   \n",
       "7   Hierarchical matching with side information fo...   \n",
       "10            Subcategory-Aware Object Classification   \n",
       "12             Describing objects by their attributes   \n",
       "17  Negative Evidences and Co-occurences in Image ...   \n",
       "19  Aggregating Local Image Descriptors into Compa...   \n",
       "20  Blocks That Shout: Distinctive Parts for Scene...   \n",
       "22  Attribute-Based Classification for Zero-Shot V...   \n",
       "24  Harvesting Mid-level Visual Concepts from Larg...   \n",
       "26  Automated Flower Classification over a Large N...   \n",
       "27        Scalable Recognition with a Vocabulary Tree   \n",
       "28  Learning and Transferring Mid-level Image Repr...   \n",
       "30        Reconfigurable models for scene recognition   \n",
       "33  Object retrieval with large vocabularies and f...   \n",
       "34  Lost in quantization: Improving particular obj...   \n",
       "35                          Recognizing indoor scenes   \n",
       "36  A database for fine grained activity detection...   \n",
       "38  Contextualizing object detection and classific...   \n",
       "39  Learning Discriminative Part Detectors for Ima...   \n",
       "40  DeepFace: Closing the Gap to Human-Level Perfo...   \n",
       "41  To Aggregate or Not to aggregate: Selective Ma...   \n",
       "42  DeepPose: Human Pose Estimation via Deep Neura...   \n",
       "43  Sparse Representations and Distance Learning f...   \n",
       "45  A Discriminative Latent Model of Object Classe...   \n",
       "46  Combining randomization and discrimination for...   \n",
       "50  PANDA: Pose Aligned Networks for Deep Attribut...   \n",
       "51  Oriented pooling for dense and non-dense rotat...   \n",
       "\n",
       "                                               URL  \n",
       "0      http://dx.doi.org/10.1007/s11263-015-0816-y  \n",
       "1          http://dx.doi.org/10.1109/cvpr.2013.110  \n",
       "3          http://dx.doi.org/10.1109/cvpr.2013.207  \n",
       "4          http://dx.doi.org/10.1109/cvpr.2013.128  \n",
       "5      http://dx.doi.org/10.1109/iccv.2011.6126413  \n",
       "6      http://dx.doi.org/10.1109/iccv.2011.6126546  \n",
       "7      http://dx.doi.org/10.1109/cvpr.2012.6248083  \n",
       "10         http://dx.doi.org/10.1109/cvpr.2013.112  \n",
       "12    http://dx.doi.org/10.1109/cvprw.2009.5206772  \n",
       "17  http://dx.doi.org/10.1007/978-3-642-33709-3_55  \n",
       "19        http://dx.doi.org/10.1109/tpami.2011.235  \n",
       "20         http://dx.doi.org/10.1109/cvpr.2013.124  \n",
       "22        http://dx.doi.org/10.1109/tpami.2013.140  \n",
       "24         http://dx.doi.org/10.1109/cvpr.2013.115  \n",
       "26        http://dx.doi.org/10.1109/icvgip.2008.47  \n",
       "27         http://dx.doi.org/10.1109/cvpr.2006.264  \n",
       "28         http://dx.doi.org/10.1109/cvpr.2014.222  \n",
       "30     http://dx.doi.org/10.1109/cvpr.2012.6248001  \n",
       "33      http://dx.doi.org/10.1109/cvpr.2007.383172  \n",
       "34     http://dx.doi.org/10.1109/cvpr.2008.4587635  \n",
       "35     http://dx.doi.org/10.1109/cvpr.2009.5206537  \n",
       "36     http://dx.doi.org/10.1109/cvpr.2012.6247801  \n",
       "38     http://dx.doi.org/10.1109/cvpr.2011.5995330  \n",
       "39         http://dx.doi.org/10.1109/iccv.2013.422  \n",
       "40         http://dx.doi.org/10.1109/cvpr.2014.220  \n",
       "41         http://dx.doi.org/10.1109/iccv.2013.177  \n",
       "42         http://dx.doi.org/10.1109/cvpr.2014.214  \n",
       "43   http://dx.doi.org/10.1007/978-3-642-35749-7_3  \n",
       "45  http://dx.doi.org/10.1007/978-3-642-15555-0_12  \n",
       "46     http://dx.doi.org/10.1109/cvpr.2011.5995368  \n",
       "50         http://dx.doi.org/10.1109/cvpr.2014.212  \n",
       "51               http://dx.doi.org/10.5244/c.27.99  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:19,  6.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1': 'tmp/627ea2fa-d138-4da2-b063-ea483ab9d399//papers/1310.1531v1.pdf',\n",
       " '4': 'tmp/627ea2fa-d138-4da2-b063-ea483ab9d399//papers/1312.4659v3.pdf',\n",
       " '5': 'tmp/627ea2fa-d138-4da2-b063-ea483ab9d399//papers/1311.5591v2.pdf'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_pdf = download_papers(retrieve_df, working_dir)\n",
    "reference_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_boxes = extract_element_boxes(paper_path, get_citation=True)\n",
    "\n",
    "cite_boxes = []\n",
    "for i, element_info in enumerate(element_boxes):\n",
    "    if \"citations\" in element_info.keys():\n",
    "        cite_boxes.append(element_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_refs[0]\n",
    "results = crossref_search(parsed_refs[0][\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['indexed', 'reference-count', 'publisher', 'issue', 'license', 'content-domain', 'short-container-title', 'published-print', 'DOI', 'type', 'created', 'page', 'update-policy', 'source', 'is-referenced-by-count', 'title', 'prefix', 'volume', 'author', 'member', 'published-online', 'reference', 'container-title', 'language', 'link', 'deposited', 'score', 'resource', 'issued', 'references-count', 'journal-issue', 'alternative-id', 'URL', 'ISSN', 'issn-type', 'published'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexed': {'date-parts': [[2024, 8, 22]],\n",
       "  'date-time': '2024-08-22T12:44:16Z',\n",
       "  'timestamp': 1724330656384},\n",
       " 'reference-count': 102,\n",
       " 'publisher': 'Springer Science and Business Media LLC',\n",
       " 'issue': '3',\n",
       " 'license': [{'start': {'date-parts': [[2015, 4, 11]],\n",
       "    'date-time': '2015-04-11T00:00:00Z',\n",
       "    'timestamp': 1428710400000},\n",
       "   'content-version': 'tdm',\n",
       "   'delay-in-days': 0,\n",
       "   'URL': 'http://www.springer.com/tdm'}],\n",
       " 'content-domain': {'domain': ['link.springer.com'],\n",
       "  'crossmark-restriction': False},\n",
       " 'short-container-title': ['Int J Comput Vis'],\n",
       " 'published-print': {'date-parts': [[2015, 12]]},\n",
       " 'DOI': '10.1007/s11263-015-0816-y',\n",
       " 'type': 'journal-article',\n",
       " 'created': {'date-parts': [[2015, 4, 10]],\n",
       "  'date-time': '2015-04-10T04:47:45Z',\n",
       "  'timestamp': 1428641265000},\n",
       " 'page': '211-252',\n",
       " 'update-policy': 'http://dx.doi.org/10.1007/springer_crossmark_policy',\n",
       " 'source': 'Crossref',\n",
       " 'is-referenced-by-count': 24474,\n",
       " 'title': ['ImageNet Large Scale Visual Recognition Challenge'],\n",
       " 'prefix': '10.1007',\n",
       " 'volume': '115',\n",
       " 'author': [{'given': 'Olga',\n",
       "   'family': 'Russakovsky',\n",
       "   'sequence': 'first',\n",
       "   'affiliation': []},\n",
       "  {'given': 'Jia',\n",
       "   'family': 'Deng',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': []},\n",
       "  {'given': 'Hao',\n",
       "   'family': 'Su',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': []},\n",
       "  {'given': 'Jonathan',\n",
       "   'family': 'Krause',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': []},\n",
       "  {'given': 'Sanjeev',\n",
       "   'family': 'Satheesh',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': []},\n",
       "  {'given': 'Sean',\n",
       "   'family': 'Ma',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': []},\n",
       "  {'given': 'Zhiheng',\n",
       "   'family': 'Huang',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': []},\n",
       "  {'given': 'Andrej',\n",
       "   'family': 'Karpathy',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': []},\n",
       "  {'given': 'Aditya',\n",
       "   'family': 'Khosla',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': []},\n",
       "  {'given': 'Michael',\n",
       "   'family': 'Bernstein',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': []},\n",
       "  {'given': 'Alexander C.',\n",
       "   'family': 'Berg',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': []},\n",
       "  {'given': 'Li',\n",
       "   'family': 'Fei-Fei',\n",
       "   'sequence': 'additional',\n",
       "   'affiliation': []}],\n",
       " 'member': '297',\n",
       " 'published-online': {'date-parts': [[2015, 4, 11]]},\n",
       " 'reference': [{'issue': '14',\n",
       "   'key': '816_CR1',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '2037',\n",
       "   'DOI': '10.1109/TPAMI.2006.244',\n",
       "   'volume': '28',\n",
       "   'author': 'T Ahonen',\n",
       "   'year': '2006',\n",
       "   'unstructured': 'Ahonen, T., Hadid, A., & Pietikinen, M. (2006). Face description with local binary patterns: Application to face recognition. Pattern Analysis and Machine Intelligence, 28(14), 2037–2041.',\n",
       "   'journal-title': 'Pattern Analysis and Machine Intelligence'},\n",
       "  {'issue': '11',\n",
       "   'key': '816_CR2',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '2189',\n",
       "   'DOI': '10.1109/TPAMI.2012.28',\n",
       "   'volume': '34',\n",
       "   'author': 'B Alexe',\n",
       "   'year': '2012',\n",
       "   'unstructured': 'Alexe, B., Deselares, T., & Ferrari, V. (2012). Measuring the objectness of image windows. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(11), 2189–2202.',\n",
       "   'journal-title': 'IEEE Transactions on Pattern Analysis and Machine Intelligence'},\n",
       "  {'key': '816_CR3',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Arandjelovic, R., & Zisserman, A. (2012). Three things everyone should know to improve object retrieval. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2012.6248018'},\n",
       "  {'key': '816_CR4',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Arbeláez, P., Pont-Tuset, J., Barron, J., Marques, F., & Malik, J. (2014). Multiscale combinatorial grouping. In Computer vision and pattern recognition.',\n",
       "   'DOI': '10.1109/CVPR.2014.49'},\n",
       "  {'key': '816_CR5',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '898',\n",
       "   'DOI': '10.1109/TPAMI.2010.161',\n",
       "   'volume': '33',\n",
       "   'author': 'P Arbelaez',\n",
       "   'year': '2011',\n",
       "   'unstructured': 'Arbelaez, P., Maire, M., Fowlkes, C., & Malik, J. (2011). Contour detection and hierarchical image segmentation. IEEE Transaction on Pattern Analysis and Machine Intelligence, 33, 898–916.',\n",
       "   'journal-title': 'IEEE Transaction on Pattern Analysis and Machine Intelligence'},\n",
       "  {'key': '816_CR6',\n",
       "   'unstructured': 'Batra, D., Agrawal, H., Banik, P., Chavali, N., Mathialagan, C. S., & Alfadda, A. (2013). Cloudcv: Large-scale distributed computer vision as a cloud service.'},\n",
       "  {'key': '816_CR7',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Bell, S., Upchurch, P., Snavely, N., & Bala, K. (2013). OpenSurfaces: A richly annotated catalog of surface appearance. In ACM transactions on graphics (SIGGRAPH).',\n",
       "   'DOI': '10.1145/2461912.2462002'},\n",
       "  {'key': '816_CR8',\n",
       "   'unstructured': 'Berg, A., Farrell, R., Khosla, A., Krause, J., Fei-Fei, L., Li, J., & Maji, S. (2013). Fine-grained competition. https://sites.google.com/site/fgcomp2013/ .'},\n",
       "  {'key': '816_CR9',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Chatfield, K., Simonyan, K., Vedaldi, A., & Zisserman, A. (2014). Return of the devil in the details: Delving deep into convolutional nets. CoRR, abs/1405.3531.',\n",
       "   'DOI': '10.5244/C.28.6'},\n",
       "  {'key': '816_CR10',\n",
       "   'unstructured': 'Chen, Q., Song, Z., Huang, Z., Hua, Y., & Yan, S. (2014). Contextualizing object detection and classification. In CVPR.'},\n",
       "  {'key': '816_CR11',\n",
       "   'first-page': '551',\n",
       "   'volume': '7',\n",
       "   'author': 'K Crammer',\n",
       "   'year': '2006',\n",
       "   'unstructured': 'Crammer, K., Dekel, O., Keshet, J., Shalev-Shwartz, S., & Singer, Y. (2006). Online passive-aggressive algorithms. Journal of Machine Learning Research, 7, 551–585.',\n",
       "   'journal-title': 'Journal of Machine Learning Research'},\n",
       "  {'key': '816_CR12',\n",
       "   'unstructured': 'Criminisi, A. (2004). Microsoft Research Cambridge (MSRC) object recognition image database (version 2.0). http://research.microsoft.com/vision/cambridge/recognition .'},\n",
       "  {'key': '816_CR13',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Dean, T., Ruzon, M., Segal, M., Shlens, J., Vijayanarasimhan, S., & Yagnik, J. (2013). Fast, accurate detection of 100,000 object classes on a single machine. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2013.237'},\n",
       "  {'key': '816_CR14',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., & Fei-Fei, L. (2009). ImageNet: A large-scale hierarchical image database. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2009.5206848'},\n",
       "  {'key': '816_CR15',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Deng, J., Russakovsky, O., Krause, J., Bernstein, M., Berg, A. C., & Fei-Fei, L. (2014). Scalable multi-label annotation. In CHI.',\n",
       "   'DOI': '10.1145/2556288.2557011'},\n",
       "  {'key': '816_CR16',\n",
       "   'unstructured': 'Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., & Darrell, T. (2013). Decaf: A deep convolutional activation feature for generic visual recognition. CoRR, abs/1310.1531.'},\n",
       "  {'key': '816_CR17',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Dubout, C., & Fleuret, F. (2012). Exact acceleration of linear object detectors. In Proceedings of the European conference on computer vision (ECCV).',\n",
       "   'DOI': '10.1007/978-3-642-33712-3_22'},\n",
       "  {'key': '816_CR18',\n",
       "   'unstructured': 'Everingham, M., Gool, L. V., Williams, C., Winn, J., & Zisserman, A. (2005–2012). PASCAL Visual Object Classes Challenge (VOC). http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html .'},\n",
       "  {'issue': '2',\n",
       "   'key': '816_CR19',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '303',\n",
       "   'DOI': '10.1007/s11263-009-0275-4',\n",
       "   'volume': '88',\n",
       "   'author': 'M Everingham',\n",
       "   'year': '2010',\n",
       "   'unstructured': 'Everingham, M., Van Gool, L., Williams, C. K. I., Winn, J., & Zisserman, A. (2010). The Pascal Visual Object Classes (VOC) challenge. International Journal of Computer Vision, 88(2), 303–338.',\n",
       "   'journal-title': 'International Journal of Computer Vision'},\n",
       "  {'key': '816_CR20',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '98',\n",
       "   'DOI': '10.1007/s11263-014-0733-5',\n",
       "   'volume': '111',\n",
       "   'author': 'M Everingham',\n",
       "   'year': '2014',\n",
       "   'unstructured': 'Everingham, M., Eslami, S. M. A., Van Gool, L., Williams, C. K. I., Winn, J., & Zisserman, A. (2014). The Pascal Visual Object Classes (VOC) challenge—A retrospective. International Journal of Computer Vision, 111, 98–136.',\n",
       "   'journal-title': 'International Journal of Computer Vision'},\n",
       "  {'key': '816_CR21',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Fei-Fei, L., & Perona, P. (2005). A Bayesian hierarchical model for learning natural scene categories. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2005.16'},\n",
       "  {'key': '816_CR22',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Fei-Fei, L., Fergus, R., & Perona, P. (2004). Learning generative visual models from few examples: An incremental bayesian approach tested on 101 object categories. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2004.383'},\n",
       "  {'issue': '9',\n",
       "   'key': '816_CR23',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '1627',\n",
       "   'DOI': '10.1109/TPAMI.2009.167',\n",
       "   'volume': '32',\n",
       "   'author': 'P Felzenszwalb',\n",
       "   'year': '2010',\n",
       "   'unstructured': 'Felzenszwalb, P., Girshick, R., McAllester, D., & Ramanan, D. (2010). Object detection with discriminatively trained part based models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(9), 1627–1645.',\n",
       "   'journal-title': 'IEEE Transactions on Pattern Analysis and Machine Intelligence'},\n",
       "  {'key': '816_CR24',\n",
       "   'unstructured': 'Frome, A., Corrado, G., Shlens, J., Bengio, S., Dean, J., Ranzato, M., & Mikolov, T. (2013). Devise: A deep visual-semantic embedding model. In Advances in neural information processing systems, NIPS.'},\n",
       "  {'key': '816_CR25',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '1231',\n",
       "   'DOI': '10.1177/0278364913491297',\n",
       "   'volume': '32',\n",
       "   'author': 'A Geiger',\n",
       "   'year': '2013',\n",
       "   'unstructured': 'Geiger, A., Lenz, P., Stiller, C., & Urtasun, R. (2013). Vision meets robotics: The kitti dataset. International Journal of Robotics Research, 32, 1231–1237.',\n",
       "   'journal-title': 'International Journal of Robotics Research'},\n",
       "  {'key': '816_CR26',\n",
       "   'unstructured': 'Girshick, R. B., Donahue, J., Darrell, T., & Malik, J. (2013). Rich feature hierarchies for accurate object detection and semantic segmentation (v4). CoRR.'},\n",
       "  {'key': '816_CR27',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Girshick, R., Donahue, J., Darrell, T., & Malik., J. (2014). Rich feature hierarchies for accurate object detection and semantic segmentation. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2014.81'},\n",
       "  {'key': '816_CR28',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Gould, S., Fulton, R., & Koller, D. (2009). Decomposing a scene into geometric and semantically consistent regions. In ICCV.',\n",
       "   'DOI': '10.1109/ICCV.2009.5459211'},\n",
       "  {'key': '816_CR29',\n",
       "   'unstructured': 'Graham, B. (2013). Sparse arrays of signatures for online character recognition. CoRR.'},\n",
       "  {'key': '816_CR30',\n",
       "   'unstructured': 'Griffin, G., Holub, A., & Perona, P. (2007). Caltech-256 object category dataset. Technical report 7694, Caltech.'},\n",
       "  {'key': '816_CR31',\n",
       "   'unstructured': 'Harada, T., & Kuniyoshi, Y. (2012). Graphical Gaussian vector for image categorization. In NIPS.'},\n",
       "  {'key': '816_CR32',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Harel, J., Koch, C., & Perona, P. (2007). Graph-based visual saliency. In NIPS.',\n",
       "   'DOI': '10.7551/mitpress/7503.003.0073'},\n",
       "  {'key': '816_CR33',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'He, K., Zhang, X., Ren, S., & Su, J. (2014). Spatial pyramid pooling in deep convolutional networks for visual recognition. In ECCV.',\n",
       "   'DOI': '10.1007/978-3-319-10578-9_23'},\n",
       "  {'key': '816_CR34',\n",
       "   'unstructured': 'Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2012). Improving neural networks by preventing co-adaptation of feature detectors. CoRR, abs/1207.0580.'},\n",
       "  {'key': '816_CR35',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Hoiem, D., Chodpathumwan, Y., & Dai, Q. (2012). Diagnosing error in object detectors. In ECCV.',\n",
       "   'DOI': '10.1007/978-3-642-33712-3_25'},\n",
       "  {'key': '816_CR36',\n",
       "   'unstructured': 'Howard, A. (2014). Some improvements on deep convolutional neural network based image classification. In ICLR.'},\n",
       "  {'key': '816_CR37',\n",
       "   'unstructured': 'Huang, G. B., Ramesh, M., Berg, T., & Learned-Miller, E. (2007). Labeled faces in the wild: A database for studying face recognition in unconstrained environments. Technical report 07–49, University of Massachusetts, Amherst.'},\n",
       "  {'key': '816_CR38',\n",
       "   'unstructured': 'Iandola, F. N., Moskewicz, M. W., Karayev, S., Girshick, R. B., Darrell, T., & Keutzer, K. (2014). Densenet: Implementing efficient convnet descriptor pyramids. CoRR.'},\n",
       "  {'key': '816_CR39',\n",
       "   'unstructured': 'Jia, Y. (2013). Caffe: An open source convolutional architecture for fast feature embedding. http://caffe.berkeleyvision.org/ .'},\n",
       "  {'key': '816_CR40',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Jojic, N., Frey, B. J., & Kannan, A. (2003). Epitomic analysis of appearance and shape. In ICCV.',\n",
       "   'DOI': '10.1109/ICCV.2003.1238311'},\n",
       "  {'key': '816_CR41',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Kanezaki, A., Inaba, S., Ushiku, Y., Yamashita, Y., Muraoka, H., Kuniyoshi, Y., & Harada, T. (2014). Hard negative classes for multiple object detection. In ICRA.',\n",
       "   'DOI': '10.1109/ICRA.2014.6907300'},\n",
       "  {'key': '816_CR42',\n",
       "   'unstructured': 'Khosla, A., Jayadevaprakash, N., Yao, B., & Fei-Fei, L. (2011). Novel dataset for fine-grained image categorization. In First workshop on fine-grained visual categorization, CVPR.'},\n",
       "  {'key': '816_CR43',\n",
       "   'unstructured': 'Krizhevsky, A., Sutskever, I., & Hinton, G. (2012). ImageNet classification with deep convolutional neural networks. In NIPS.'},\n",
       "  {'key': '816_CR44',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Kuettel, D., Guillaumin, M., & Ferrari, V. (2012). Segmentation propagation in ImageNet. In ECCV.',\n",
       "   'DOI': '10.1007/978-3-642-33786-4_34'},\n",
       "  {'key': '816_CR45',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Lazebnik, S., Schmid, C., & Ponce, J. (2006). Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2006.68'},\n",
       "  {'key': '816_CR46',\n",
       "   'unstructured': 'Lin, M., Chen, Q., & Yan, S. (2014a). Network in network. In ICLR.'},\n",
       "  {'key': '816_CR47',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Lin, Y., Lv, F., Cao, L., Zhu, S., Yang, M., Cour, T., Yu, K., & Huang, T. (2011). Large-scale image classification: Fast feature extraction and SVM training. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2011.5995477'},\n",
       "  {'key': '816_CR48',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollr, P., & Zitnick, C. L. (2014b). Microsoft COCO: Common objects in context. In ECCV.',\n",
       "   'DOI': '10.1007/978-3-319-10602-1_48'},\n",
       "  {'key': '816_CR49',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '2368',\n",
       "   'DOI': '10.1109/TPAMI.2011.131',\n",
       "   'volume': '32',\n",
       "   'author': 'C Liu',\n",
       "   'year': '2011',\n",
       "   'unstructured': 'Liu, C., Yuen, J., & Torralba, A. (2011). Nonparametric scene parsing via label transfer. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32, 2368–2382.',\n",
       "   'journal-title': 'IEEE Transactions on Pattern Analysis and Machine Intelligence'},\n",
       "  {'issue': '2',\n",
       "   'key': '816_CR50',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '91',\n",
       "   'DOI': '10.1023/B:VISI.0000029664.99615.94',\n",
       "   'volume': '60',\n",
       "   'author': 'DG Lowe',\n",
       "   'year': '2004',\n",
       "   'unstructured': 'Lowe, D. G. (2004). Distinctive image features from scale-invariant keypoints. International Journal of Computer Vision, 60(2), 91–110.',\n",
       "   'journal-title': 'International Journal of Computer Vision'},\n",
       "  {'key': '816_CR51',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Maji, S., & Malik, J. (2009). Object detection using a max-margin hough transform. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2009.5206693'},\n",
       "  {'key': '816_CR52',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Manen, S., Guillaumin, M., & Van Gool, L. (2013). Prime object proposals with randomized Prim’s algorithm. In ICCV.',\n",
       "   'DOI': '10.1109/ICCV.2013.315'},\n",
       "  {'key': '816_CR53',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Mensink, T., Verbeek, J., Perronnin, F., & Csurka, G. (2012). Metric learning for large scale image classification: Generalizing to new classes at near-zero cost. In ECCV.',\n",
       "   'DOI': '10.1007/978-3-642-33709-3_35'},\n",
       "  {'key': '816_CR54',\n",
       "   'unstructured': 'Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. In ICLR.'},\n",
       "  {'issue': '11',\n",
       "   'key': '816_CR55',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '39',\n",
       "   'DOI': '10.1145/219717.219748',\n",
       "   'volume': '38',\n",
       "   'author': 'GA Miller',\n",
       "   'year': '1995',\n",
       "   'unstructured': 'Miller, G. A. (1995). Wordnet: A lexical database for English. Commun. ACM, 38(11), 39–41.',\n",
       "   'journal-title': 'Commun. ACM'},\n",
       "  {'key': '816_CR56',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Oliva, A., & Torralba, A. (2001). Modeling the shape of the scene: A holistic representation of the spatial envelope. In IJCV.',\n",
       "   'DOI': '10.1023/A:1011139631724'},\n",
       "  {'key': '816_CR57',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Ordonez, V., Deng, J., Choi, Y., Berg, A. C., & Berg, T. L. (2013). From large scale image categorization to entry-level categories. In IEEE international conference on computer vision (ICCV).',\n",
       "   'DOI': '10.1109/ICCV.2013.344'},\n",
       "  {'key': '816_CR58',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Ouyang, W., & Wang, X. (2013). Joint deep learning for pedestrian detection. In ICCV.',\n",
       "   'DOI': '10.1109/ICCV.2013.257'},\n",
       "  {'key': '816_CR59',\n",
       "   'unstructured': 'Ouyang, W., Luo, P., Zeng, X., Qiu, S., Tian, Y., Li, H., Yang, S., Wang, Z., Xiong, Y., Qian, C., Zhu, Z., Wang, R., Loy, C. C., Wang, X., & Tang, X. (2014). Deepid-net: multi-stage and deformable deep convolutional neural networks for object detection. CoRR, abs/1409.3505.'},\n",
       "  {'key': '816_CR60',\n",
       "   'unstructured': 'Papandreou, G. (2014). Deep epitomic convolutional neural networks. CoRR.'},\n",
       "  {'key': '816_CR61',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Papandreou, G., Chen, L.-C., & Yuille, A. L. (2014). Modeling image patches with a generic dictionary of mini-epitomes.',\n",
       "   'DOI': '10.1109/CVPR.2014.264'},\n",
       "  {'key': '816_CR62',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Perronnin, F., & Dance, C. R. (2007). Fisher kernels on visual vocabularies for image categorization. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2007.383266'},\n",
       "  {'key': '816_CR63',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Perronnin, F., Akata, Z., Harchaoui, Z., & Schmid, C. (2012). Towards good practice in large-scale learning for image classification. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2012.6248090'},\n",
       "  {'key': '816_CR64',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Perronnin, F., Sánchez, J., & Mensink, T. (2010). Improving the fisher kernel for large-scale image classification. In ECCV (4).',\n",
       "   'DOI': '10.1007/978-3-642-15561-1_11'},\n",
       "  {'key': '816_CR65',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Russakovsky, O., Deng, J., Huang, Z., Berg, A., & Fei-Fei, L. (2013). Detecting avocados to zucchinis: What have we done, & where are we going? In ICCV.',\n",
       "   'DOI': '10.1109/ICCV.2013.258'},\n",
       "  {'key': '816_CR66',\n",
       "   'unstructured': 'Russell, B., Torralba, A., Murphy, K., & Freeman, W. T. (2007). LabelMe: A database and web-based tool for image annotation. In IJCV.'},\n",
       "  {'key': '816_CR67',\n",
       "   'unstructured': 'Sanchez, J., & Perronnin, F. (2011). High-dim. signature compression for large-scale image classification. In CVPR.'},\n",
       "  {'key': '816_CR68',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Sanchez, J., Perronnin, F., & de Campos, T. (2012). Modeling spatial layout of images beyond spatial pyramids. In PRL.',\n",
       "   'DOI': '10.1016/j.patrec.2012.07.019'},\n",
       "  {'key': '816_CR69',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Scheirer, W., Kumar, N., Belhumeur, P. N., & Boult, T. E. (2012). Multi-attribute spaces: Calibration for attribute fusion and similarity search. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2012.6248021'},\n",
       "  {'key': '816_CR70',\n",
       "   'unstructured': 'Schmidhuber, J. (2012). Multi-column deep neural networks for image classification. In CVPR.'},\n",
       "  {'key': '816_CR71',\n",
       "   'unstructured': 'Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., & LeCun, Y. (2013). Overfeat: Integrated recognition, localization and detection using convolutional networks. CoRR, abs/1312.6229.'},\n",
       "  {'key': '816_CR72',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Sheng, V. S., Provost, F., & Ipeirotis, P. G. (2008). Get another label? Improving data quality and data mining using multiple, noisy labelers. In SIGKDD.',\n",
       "   'DOI': '10.1145/1401890.1401965'},\n",
       "  {'key': '816_CR73',\n",
       "   'unstructured': 'Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556.'},\n",
       "  {'key': '816_CR74',\n",
       "   'unstructured': 'Simonyan, K., Vedaldi, A., & Zisserman, A. (2013). Deep fisher networks for large-scale image classification. In NIPS.'},\n",
       "  {'key': '816_CR75',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Sorokin, A., & Forsyth, D. (2008). Utility data annotation with Amazon Mechanical Turk. In InterNet08.',\n",
       "   'DOI': '10.1109/CVPRW.2008.4562953'},\n",
       "  {'key': '816_CR76',\n",
       "   'unstructured': 'Su, H., Deng, J., & Fei-Fei, L. (2012). Crowdsourcing annotations for visual object detection. In AAAI human computation workshop.'},\n",
       "  {'key': '816_CR77',\n",
       "   'unstructured': 'Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., & Rabinovich, A. (2014). Going deeper with convolutions. Technical report.'},\n",
       "  {'key': '816_CR78',\n",
       "   'unstructured': 'Tang, Y. (2013). Deep learning using support vector machines. CoRR, abs/1306.0239.'},\n",
       "  {'issue': '6582',\n",
       "   'key': '816_CR79',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '520',\n",
       "   'DOI': '10.1038/381520a0',\n",
       "   'volume': '381',\n",
       "   'author': 'S Thorpe',\n",
       "   'year': '1996',\n",
       "   'unstructured': 'Thorpe, S., Fize, D., Marlot, C., et al. (1996). Speed of processing in the human visual system. Nature, 381(6582), 520–522.',\n",
       "   'journal-title': 'Nature'},\n",
       "  {'key': '816_CR80',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Torralba, A., & Efros, A. A. (2011). Unbiased look at dataset bias. In CVPR’11.',\n",
       "   'DOI': '10.1109/CVPR.2011.5995347'},\n",
       "  {'key': '816_CR81',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '1958',\n",
       "   'DOI': '10.1109/TPAMI.2008.128',\n",
       "   'volume': '30',\n",
       "   'author': 'A Torralba',\n",
       "   'year': '2008',\n",
       "   'unstructured': 'Torralba, A., Fergus, R., & Freeman, W. (2008). 80 million tiny images: A large data set for nonparametric object and scene recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 30, 1958–1970.',\n",
       "   'journal-title': 'IEEE Transactions on Pattern Analysis and Machine Intelligence'},\n",
       "  {'key': '816_CR82',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '154',\n",
       "   'DOI': '10.1007/s11263-013-0620-5',\n",
       "   'volume': '104',\n",
       "   'author': 'J Uijlings',\n",
       "   'year': '2013',\n",
       "   'unstructured': 'Uijlings, J., van de Sande, K., Gevers, T., & Smeulders, A. (2013). Selective search for object recognition. International Journal of Computer Vision, 104, 154–171.',\n",
       "   'journal-title': 'International Journal of Computer Vision'},\n",
       "  {'key': '816_CR83',\n",
       "   'unstructured': 'Urtasun, R., Fergus, R., Hoiem, D., Torralba, A., Geiger, A., Lenz, P., Silberman, N., Xiao, J., & Fidler, S. (2013–2014). Reconstruction meets recognition challenge. http://ttic.uchicago.edu/rurtasun/rmrc/ .'},\n",
       "  {'key': '816_CR84',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'van de Sande, K. E. A., Snoek, C. G. M., & Smeulders, A. W. M. (2014). Fisher and vlad with flair. In Proceedings of the IEEE conference on computer vision and pattern recognition.',\n",
       "   'DOI': '10.1109/CVPR.2014.304'},\n",
       "  {'key': '816_CR85',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'van de Sande, K. E. A., Uijlings, J. R. R., Gevers, T., & Smeulders, A. W. M. (2011b). Segmentation as selective search for object recognition. In ICCV.',\n",
       "   'DOI': '10.1109/ICCV.2011.6126456'},\n",
       "  {'issue': '9',\n",
       "   'key': '816_CR86',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '1582',\n",
       "   'DOI': '10.1109/TPAMI.2009.154',\n",
       "   'volume': '32',\n",
       "   'author': 'KEA Sande van de',\n",
       "   'year': '2010',\n",
       "   'unstructured': 'van de Sande, K. E. A., Gevers, T., & Snoek, C. G. M. (2010). Evaluating color descriptors for object and scene recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(9), 1582–1596.',\n",
       "   'journal-title': 'IEEE Transactions on Pattern Analysis and Machine Intelligence'},\n",
       "  {'issue': '1',\n",
       "   'key': '816_CR87',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'first-page': '60',\n",
       "   'DOI': '10.1109/TMM.2010.2091400',\n",
       "   'volume': '13',\n",
       "   'author': 'KEA Sande van de',\n",
       "   'year': '2011',\n",
       "   'unstructured': 'van de Sande, K. E. A., Gevers, T., & Snoek, C. G. M. (2011a). Empowering visual categorization with the GPU. IEEE Transactions on Multimedia, 13(1), 60–70.',\n",
       "   'journal-title': 'IEEE Transactions on Multimedia'},\n",
       "  {'key': '816_CR88',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Vittayakorn, S., & Hays, J. (2011). Quality assessment for crowdsourced object annotations. In BMVC.',\n",
       "   'DOI': '10.5244/C.25.109'},\n",
       "  {'key': '816_CR89',\n",
       "   'unstructured': 'von Ahn, L., & Dabbish, L. (2005). Esp: Labeling images with a computer game. In AAAI spring symposium: Knowledge collection from volunteer contributors.'},\n",
       "  {'key': '816_CR90',\n",
       "   'first-page': '184',\n",
       "   'volume': '1010',\n",
       "   'author': 'C Vondrick',\n",
       "   'year': '2012',\n",
       "   'unstructured': 'Vondrick, C., Patterson, D., & Ramanan, D. (2012). Efficiently scaling up crowdsourced video annotation. International Journal of Computer Vision, 1010, 184–204.',\n",
       "   'journal-title': 'International Journal of Computer Vision'},\n",
       "  {'key': '816_CR91',\n",
       "   'unstructured': 'Wan, L., Zeiler, M., Zhang, S., LeCun, Y., & Fergus, R. (2013). Regularization of neural networks using dropconnect. In Proceedings of the international conference on machine learning (ICML’13).'},\n",
       "  {'key': '816_CR92',\n",
       "   'unstructured': 'Wang, M., Xiao, T., Li, J., Hong, C., Zhang, J., & Zhang, Z. (2014). Minerva: A scalable and highly efficient training platform for deep learning. In APSys.'},\n",
       "  {'key': '816_CR93',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Wang, J., Yang, J., Yu, K., Lv, F., Huang, T., & Gong, Y. (2010). Locality-constrained linear coding for image classification. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2010.5540018'},\n",
       "  {'key': '816_CR94',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Wang, X., Yang, M., Zhu, S., & Lin, Y. (2013). Regionlets for generic object detection. In ICCV.',\n",
       "   'DOI': '10.1109/ICCV.2013.10'},\n",
       "  {'key': '816_CR95',\n",
       "   'unstructured': 'Welinder, P., Branson, S., Belongie, S., & Perona, P. (2010). The multidimensional wisdom of crowds. In NIPS.'},\n",
       "  {'key': '816_CR96',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Xiao, J., Hays, J., Ehinger, K., Oliva, A., & Torralba., A. (2010). SUN database: Large-scale scene recognition from Abbey to Zoo. In CVPR.',\n",
       "   'DOI': '10.1109/CVPR.2010.5539970'},\n",
       "  {'key': '816_CR97',\n",
       "   'unstructured': 'Yang, J., Yu, K., Gong, Y., & Huang, T. (2009). Linear spatial pyramid matching using sparse coding for image classification. In CVPR.'},\n",
       "  {'key': '816_CR98',\n",
       "   'volume-title': 'Introduction to a large scale general purpose ground truth dataset: methodology, annotation tool, and benchmarks',\n",
       "   'author': 'B Yao',\n",
       "   'year': '2007',\n",
       "   'unstructured': 'Yao, B., Yang, X., & Zhu, S.-C. (2007). Introduction to a large scale general purpose ground truth dataset: methodology, annotation tool, and benchmarks. Berlin: Springer.'},\n",
       "  {'key': '816_CR99',\n",
       "   'unstructured': 'Zeiler, M. D., & Fergus, R. (2013). Visualizing and understanding convolutional networks. CoRR, abs/1311.2901.'},\n",
       "  {'key': '816_CR100',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Zeiler, M. D., Taylor, G. W., & Fergus, R. (2011). Adaptive deconvolutional networks for mid and high level feature learning. In ICCV.',\n",
       "   'DOI': '10.1109/ICCV.2011.6126474'},\n",
       "  {'key': '816_CR101',\n",
       "   'unstructured': 'Zhou, B., Lapedriza, A., Xiao, J., Torralba, A., & Oliva, A. (2014). Learning deep features for scene recognition using places database. In NIPS.'},\n",
       "  {'key': '816_CR102',\n",
       "   'doi-asserted-by': 'crossref',\n",
       "   'unstructured': 'Zhou, X., Yu, K., Zhang, T., & Huang, T. (2010). Image classification using super-vector coding of local image descriptors. In ECCV.',\n",
       "   'DOI': '10.1007/978-3-642-15555-0_11'}],\n",
       " 'container-title': ['International Journal of Computer Vision'],\n",
       " 'language': 'en',\n",
       " 'link': [{'URL': 'http://link.springer.com/content/pdf/10.1007/s11263-015-0816-y.pdf',\n",
       "   'content-type': 'application/pdf',\n",
       "   'content-version': 'vor',\n",
       "   'intended-application': 'text-mining'},\n",
       "  {'URL': 'http://link.springer.com/article/10.1007/s11263-015-0816-y/fulltext.html',\n",
       "   'content-type': 'text/html',\n",
       "   'content-version': 'vor',\n",
       "   'intended-application': 'text-mining'},\n",
       "  {'URL': 'http://link.springer.com/content/pdf/10.1007/s11263-015-0816-y',\n",
       "   'content-type': 'unspecified',\n",
       "   'content-version': 'vor',\n",
       "   'intended-application': 'similarity-checking'}],\n",
       " 'deposited': {'date-parts': [[2023, 8, 9]],\n",
       "  'date-time': '2023-08-09T10:00:30Z',\n",
       "  'timestamp': 1691575230000},\n",
       " 'score': 35.478554,\n",
       " 'resource': {'primary': {'URL': 'http://link.springer.com/10.1007/s11263-015-0816-y'}},\n",
       " 'issued': {'date-parts': [[2015, 4, 11]]},\n",
       " 'references-count': 102,\n",
       " 'journal-issue': {'issue': '3',\n",
       "  'published-print': {'date-parts': [[2015, 12]]}},\n",
       " 'alternative-id': ['816'],\n",
       " 'URL': 'http://dx.doi.org/10.1007/s11263-015-0816-y',\n",
       " 'ISSN': ['0920-5691', '1573-1405'],\n",
       " 'issn-type': [{'value': '0920-5691', 'type': 'print'},\n",
       "  {'value': '1573-1405', 'type': 'electronic'}],\n",
       " 'published': {'date-parts': [[2015, 4, 11]]}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
